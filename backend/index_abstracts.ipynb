{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = es.Elasticsearch(hosts=['localhost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'PK0wP8RZTDmwz3nJ4WTUiw',\n",
       " 'name': 'WFfEHU-',\n",
       " 'tagline': 'You Know, for Search',\n",
       " 'version': {'build_date': '2017-10-06T20:33:39.012Z',\n",
       "  'build_hash': '1a2f265',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '6.6.1',\n",
       "  'number': '5.6.3'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_filename(fn):\n",
    "    splitted = fn.split('/')\n",
    "    versioned_id = splitted[-1].replace('.tex', '')\n",
    "    category = splitted[-2]\n",
    "    clean_id = versioned_id.split('v')[0]\n",
    "    return clean_id, category, versioned_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_utf8(line):\n",
    "    if type(line) is str:\n",
    "        return line\n",
    "    else:\n",
    "        return line.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_abstract_and_title(lines):\n",
    "    abstract = [];\n",
    "    in_abstract = False\n",
    "    title = ''\n",
    "    for line in lines:\n",
    "        # line = ensure_utf8(line)\n",
    "        if 'end{abstract}' in line:\n",
    "            in_abstract = False\n",
    "        if in_abstract:\n",
    "            abstract.append(line)\n",
    "        elif r'\\title{' in line:\n",
    "            title = line.replace(r'\\title{', '').replace('}', '')\n",
    "        if 'begin{abstract}' in line:\n",
    "            in_abstract = True\n",
    "    return ' '.join(abstract), title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae50323243465b9bbcd4c773bcdcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "abstracts = []\n",
    "for fn in tqdm(glob.glob('data/*/*.tex')):\n",
    "    with open(fn, 'rt') as f:\n",
    "        try:\n",
    "            abstract, title = extract_abstract_and_title(f.readlines())\n",
    "            if not abstract.strip():\n",
    "                continue\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    clean_id, category, versioned_id = split_filename(fn)\n",
    "    abstracts.append(\n",
    "    {\n",
    "        'clean_id': clean_id,\n",
    "        'category': category,\n",
    "        'versioned_id': versioned_id,\n",
    "        'file': fn,\n",
    "        'abstract': abstract,\n",
    "        'title': title if title else category + '/' + clean_id\n",
    "    }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148840"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ops_iter(abstracts):\n",
    "    for abstract in abstracts:\n",
    "        yield {\n",
    "            '_op_type': 'index',\n",
    "            '_index': 'abstracts',\n",
    "            '_type': 'abstract',\n",
    "            '_id': abstract['clean_id'],\n",
    "            '_source': abstract\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca34ae6d053b42d2bea9fa1b9233b5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# index documents into elasticsearch\n",
    "for _ in streaming_bulk(ec, ops_iter(tqdm(abstracts)), chunk_size=10000):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20940faf8c44460897c9c1f5ee384909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare test queries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "queries = []\n",
    "p=[0.5, 0.25, 0.125, 0.1, 0.025]\n",
    "for a in tqdm(abstracts):\n",
    "    words = a['abstract'].split()\n",
    "    good_words = [word for word in words if all(map(str.isalpha, word))]\n",
    "    N = len(good_words)\n",
    "    if N > 50:\n",
    "        for _ in range(10):\n",
    "            wcnt = np.random.choice(range(1, 6), size=1, p=p)[0]\n",
    "            w = []\n",
    "            for _ in range(wcnt):\n",
    "                w.append(good_words[np.random.randint(0, N)])\n",
    "            queries.append('%20'.join(w))\n",
    "pd.DataFrame({'query': queries}).to_csv('test_queries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
